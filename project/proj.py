# COMP9334 project (19-T1) -- University of New South Wales
# Fog/cloud Computing
# Written by Jiaquan Xu

import random
from collections import defaultdict


# --------------------------------------------
# Read the txt files
# record the information into lists
# --------------------------------------------
def read_file(test_index):
    mode_file = open('mode_'+str(test_index)+'.txt','r')
    mode = mode_file.read()
    arrival = []
    para = []
    service = []
    network = []
    with open('arrival_'+str(test_index)+'.txt','r') as file:
        for line in file:
            arrival.append(float(line))
    with open('para_'+str(test_index)+'.txt','r') as file:
        for line in file:
            para.append(float(line))
    with open('service_'+str(test_index)+'.txt','r') as file:
        for line in file:
            service.append(float(line))
    with open('network_'+str(test_index)+'.txt','r') as file:
        for line in file:
            network.append(float(line))
    return mode,arrival,para,service,network


# --------------------------------------------
# Random pre-process
# make up the arrival list, service list, network list by using the parameters in text file.
# return these three lists so that I can use the trace function to simulate.
# --------------------------------------------
def random_solve(arrival,para,service,network,seed):
    random.seed(seed)
    arrival_rate = arrival[0]
    fogtimelimit = para[0]
    time_end = para[2]
    alpha_1,alpha_2,beita = service[0], service[1], service[2]
    gamma = (1-beita)/(alpha_2**(1-beita)-alpha_1**(1-beita))
    v1,v2 = network[0], network[1]
    time = 0
    arrival_1 = []
    service_1 = []
    network_1 = []
    while time < time_end:
        # inter-arrival probability distribution is exponentially distributed with arrival_rate
        interval = random.expovariate(arrival_rate)
        time += interval
        arrival_1.append(time)
        # service time in fog t is generated by the probability density function g(t)
        #       g(t) = gamma / t ** beita when alpha_1 < t < alpha_2
        #       g(t) = 0 when t < alpha_1 ot t > alpha_2
        # I will explain this part in the report.
        service_time = (random.random() * (1-beita) / gamma + alpha_1**(1-beita)) ** (1/(1-beita))
        service_1.append(service_time)
        if service_time > fogtimelimit:
            # network latency is uniformly distributed in interval (v1,v2)
            network_time = random.uniform(v1,v2)
        else:
            network_time = 0
        network_1.append(network_time)
    return arrival_1, service_1, network_1


# --------------------------------------------
# Trace Part, simulate the whole process
# Input: [arrival],[para],[service],[network]
# Output: fog_dict, network_dict, cloud_dict
# --------------------------------------------
def trace(arrival,para,service,network):
    fogtimelimit = para[0]
    fogtimetocloud=para[1]
    i = 0   # i is the index of arriving request
    # store job queue in fog, [arrival_time_in_fog, actual_remaining_service_time, remaining_service_time_in_fog, network_latency]
    job_list = []
    # store job queue in network, [arrival_time_in_fog,remaining_time_in_network,remaining_service_time_in_cloud]
    network_job = []
    # store job queue in cloud, [arrival_time_in_fog,remaining_service_time_in_cloud]
    cloud_job = []
    # {arrival_time_in_fog:departure_time_in_fog}
    fog_dict = defaultdict(float)
    # {arrival_time_in_fog:departure_time_in_network}
    net_dict = defaultdict(float)
    # {arrival_time_in_fog:departure_time_in_cloud}
    cloud_dict = defaultdict(float)

    mc = arrival[0] # the master clock
    while job_list or cloud_job or network_job or i < len(arrival):
        if i < len(arrival):
            next_arrival_time = arrival[i]
        else:
            next_arrival_time = 100000  # represent infinity
        # sort the job list according to its remaining service time
        job_list.sort(key=lambda x: x[2], reverse=True)
        cloud_job.sort(key=lambda x: x[1], reverse=True)
        network_job.sort(key = lambda x:x[1], reverse=True)

        # if there are two jobs in job list,the service rate for each job would be one half
        # update the next event time according to the job lists
        if job_list:
            next_departure_time = mc + job_list[-1][2] * len(job_list)
        else:
            next_departure_time = 100000    # represent infinity
        if network_job:
            net_dep_time = mc + network_job[-1][1]
        else:
            net_dep_time = 100000
        if cloud_job:
            cloud_dep_time = mc + cloud_job[-1][1] * len(cloud_job)
        else:
            cloud_dep_time = 100000

        # next event time is the minimum in these time
        next_event_time = min(next_arrival_time,next_departure_time,net_dep_time,cloud_dep_time)
        interval = next_event_time - mc
        mc = next_event_time
        # update the job remaining service time
        for job in job_list:
            job[1] -= interval / len(job_list)
            job[2] -= interval / len(job_list)
        for job in cloud_job:
            job[1] -= interval / len(cloud_job)
        for job in network_job:
            job[1] -= interval
        # determine which is the next event by comparing these time
        if next_arrival_time == next_event_time:
            # next event would be an arrival in fog
            if i < len(arrival):
                job_list.append([arrival[i],service[i],min(fogtimelimit,service[i]),network[i]])
            i += 1

        if next_departure_time == next_event_time:
            # next event would be departure from fog
            # maybe it will go to network
            departured_job = job_list.pop()
            remaining_time = departured_job[1] - departured_job[2]
            if remaining_time:
                # this job will go to network
                network_job.append([departured_job[0],departured_job[3],remaining_time])
            fog_dict[departured_job[0]] = mc

        if net_dep_time == next_event_time:
            # next event would be departure from network to cloud
            # that is the same time this job go into cloud
            departured_job = network_job.pop()
            net_dict[departured_job[0]] = mc
            cloud_job.append([departured_job[0],departured_job[2]*fogtimetocloud])

        if cloud_dep_time == next_event_time:
            # next event would be departure from cloud
            departured_job = cloud_job.pop()
            cloud_dict[departured_job[0]] = mc

    return fog_dict, net_dict, cloud_dict


# --------------------------------------------
# Generate output files
# --------------------------------------------
def write_file(index,seed=0):
    fog_file_name = 'fog_dep_' + str(index) + '.txt'
    net_file_name = 'net_dep_' + str(index) + '.txt'
    cloud_file_name = 'cloud_dep_' + str(index) + '.txt'
    mrt_file_name = 'mrt_' + str(index) + '.txt'
    # load the result calculated by main_process() function
    fog_result, net_result, cloud_result, mrt = main_process(index,seed)

    with open(net_file_name,'w') as net_file, \
         open(cloud_file_name,'w') as cloud_file:
        for i in range(len(net_result)):
            net_file.write(net_result[i])
            cloud_file.write(cloud_result[i])
    with open(fog_file_name, 'w') as fog_file:
        for i in range(len(fog_result)):
            fog_file.write(fog_result[i])
    with open(mrt_file_name,'w') as mrt_file:
        mrt_file.write(str(mrt))
    return


# --------------------------------------------
# Generate result in format (4 digits decimal)
# --------------------------------------------
def main_process(index,seed=0):
    print(f'Test {index} result:')
    mode, arrival, para, service, network = read_file(index)
    fog_result = []
    net_result = []
    cloud_result = []
    mrt = 0
    if mode == 'random':
        arrival_1,service_1,network_1 =random_solve(arrival, para, service, network, seed)
        fog,net,cloud = trace(arrival_1,para,service_1,network_1)
        for key in sorted(fog.keys()):
            if key in net.keys():
                if cloud[key] < para[2]:
                    print(format(key, '.4f'), format(fog[key], '.4f'), format(net[key], '.4f'), format(cloud[key], '.4f'))
                    mrt += (cloud[key] - key)
                    fog_str = str(format(key, '.4f')) + '\t' + str(format(fog[key], '.4f')) + '\n'
                    fog_result.append(fog_str)
                    net_str = str(format(key, '.4f')) + '\t' + str(format(net[key], '.4f')) + '\n'
                    net_result.append(net_str)
                    cloud_str = str(format(key, '.4f')) + '\t' + str(format(cloud[key], '.4f')) + '\n'
                    cloud_result.append(cloud_str)
            else:
                if fog[key] < para[2]:
                    print(format(key, '.4f'), format(fog[key], '.4f'))
                    mrt += (fog[key] - key)
                    fog_str = str(format(key, '.4f')) + '\t' + str(format(fog[key], '.4f')) + '\n'
                    fog_result.append(fog_str)
        mrt /= len(fog.keys())
    else:
        fog,net,cloud = trace(arrival,para,service,network)
        for key in sorted(fog.keys()):
            fog_str = str(format(key, '.4f')) + '\t' + str(format(fog[key], '.4f')) + '\n'
            fog_result.append(fog_str)
            if key in net.keys():
                print(format(key, '.4f'), format(fog[key], '.4f'), format(net[key], '.4f'), format(cloud[key], '.4f'))
                mrt += (cloud[key] - key)
                net_str = str(format(key, '.4f')) + '\t' + str(format(net[key], '.4f')) + '\n'
                cloud_str = str(format(key, '.4f')) + '\t' + str(format(cloud[key], '.4f')) + '\n'
                net_result.append(net_str)
                cloud_result.append(cloud_str)
            else:
                print(format(key, '.4f'), format(fog[key], '.4f'))
                mrt += (fog[key] - key)
        mrt /= len(fog.keys())
    print('mrt:', format(mrt, '.4f'))
    mrt = format(mrt, '.4f')
    return fog_result, net_result, cloud_result, mrt

if __name__ == '__main__':
    # generate 3 sets of output files by using test_4 , seed = 0,1,2 as input.
    # mode = 'random'
    # arrival: lambda = 5.720
    # network: v1,v2 = 1.200, 1.470
    # para: fogtimelimit,timetocloud, timeend = 0.200, 0.600, 1000.000
    # service: a1,a2,b = 0.050, 0.300, 0.740
    # seed: 0,1,2
    index = 4
    for seed in range(3):
        fog_file_name = 'reproduce_fog_dep_' + str(seed) + '.txt'
        net_file_name = 'reproduce_net_dep_' + str(seed) + '.txt'
        cloud_file_name = 'reproduce_cloud_dep_' + str(seed) + '.txt'
        mrt_file_name = 'mrt_' + str(index) + '.txt'
        fog_result, net_result, cloud_result, mrt = main_process(index, seed)
        # load the result calculated by main_process() function
        with open(net_file_name, 'w') as net_file, \
                open(cloud_file_name, 'w') as cloud_file:
            for i in range(len(net_result)):
                net_file.write(net_result[i])
                cloud_file.write(cloud_result[i])
        with open(fog_file_name, 'w') as fog_file:
            for i in range(len(fog_result)):
                fog_file.write(fog_result[i])
        with open(mrt_file_name, 'w') as mrt_file:
            mrt_file.write(str(mrt))